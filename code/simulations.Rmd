---
title: "Simulations"
author: "mira"
date: "2022/6/12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Measurement of performance:
Method performance on linear/ heteroskadestic/ spatial non-stationary data are demonstrated. The measure of performance is coverage (the rate at which the prediction interval correctly cover the true outcome). Distribution of average coverage is computed by repeating the experiment 100 times. Conditional coverage is coverage conditional on X values. Conformalised quantile regression provides better conditional coverage as the predicton intervals are adaptive to X. In comparison, conformalised mean prediction models produce same length intervals for all X, so conditional coverage may be poor even if average coverage achieves the target level.


```{r, eval=FALSE}
#library(gstat)
#library(fields)
#library(sp)

library(igraph)
library(tidyverse)
library(ggplot2)
library(viridis)
library(grf)
library(gbm)
library(randomForest)
library(bartMachine)
#library(xgboost)
#library(nnet)
#library(blockCV)
```


```{r, eval=FALSE}
 source("utils.R")
 source("gps_weightedconformal.R")
```

# Generating non-spatial data

## dataset_1
```{r data_ns_1 , eval=FALSE}
# non-spatial data, 
# linear treatment effect.
set.seed(123)
n <- 5000
d <- 5
# X_ns_1 <- matrix(rnorm(n * d), nrow = n) # norm
 X_ns_1 <- matrix(runif(n * d,-3,3), nrow = n, ncol = d) # unif [-3,3]
beta_ns_1 <- rep(1, 5)
Y1_ns_1 <- X_ns_1 %*% beta_ns_1 + rnorm(n)
plot(X_ns_1[, 2],Y1_ns_1,cex=.5)
# hist(Y1_ns_1)
Y0_ns_1 <- rnorm(n)

# ps_ns_1 <- (1 + pbeta(X_ns_1[, 1], 2, 4)) / 4 # [0.25,0.5] ?
# T_ns_1 <- as.numeric(runif(n) < ps_ns_1) # ???
 
 ps_ns_1 <- pnorm(X_ns_1[, 1]) 
 T_ns_1 <- sapply(ps_ns_1,function(x){rbinom(1,1,prob=x)})
# hist(ps_ns_1) # largely away from 0.5, good
# hist(T_ns_1)
# plot(X_ns_1[, 1],ps_ns_1)
# plot(ps_ns_1,T_ns_1)
# plot(X_ns_1[, 1],T_ns_1)
Y_ns_1 <- ifelse(T_ns_1 == 1, Y1_ns_1, Y0_ns_1)
# plot(Y0_ns_1,Y_ns_1)
save(Y_ns_1,Y1_ns_1,Y0_ns_1,X_ns_1,T_ns_1,ps_ns_1,file="datans1_5k.Rdata")
```

## dataset_2
 
Generation of Y is non-linear.

```{r data_ns_2, eval=FALSE}
# non-spatial data, 
# heteroskadestic.
set.seed(123)
n <- 5000
d <- 5
X_ns_2 <- X_ns_1 
genY_ns_2 <- function(X){
  (2 / (1+exp(-12*(X[, 1]-0.5))))*(2/(1+exp(-12*(X[, 2]-0.5))))+rnorm(n)
  }
Y1_ns_2 <- genY_ns_2(X_ns_2) 
# hist(Y1_ns_2)
plot(X_ns_2[, 1],Y1_ns_2,cex=.5) 

Y0_ns_2 <- rnorm(n)
ps_ns_2 <- ps_ns_1 
T_ns_2 <- sapply(ps_ns_2,function(x){rbinom(1,1,prob=x)})

hist(T_ns_2)
# plot(X_ns_2[, 1],T_ns_2)
# T_ns_2 <- map_dbl(1:n,function(x){rbernoulli(n=1,ps_ns_2[x])}) 
# T_ns_2 <- as.numeric(ps_ns_2 > runif(n)) 
Y_ns_2 <- ifelse(T_ns_2 == 1, Y1_ns_2, Y0_ns_2)
# plot(Y0_ns_2,Y_ns_2)

save(Y_ns_2,Y1_ns_2,Y0_ns_2,X_ns_2,T_ns_2,ps_ns_2,file="datans2_5k.Rdata")
```


# generating network (spatial) data with interference

Spatial network data is generated in the following way: Step 1. n points are randomly sampled from a unit square. All node pairs within distance band r are connected with an edge. r is chosen such that node degree distribution is reasonable. Coordinates of each pointare saved as node attributes. This creates a spatial network. Step 2. data1 or data2 are combined to the network such that each data point is assigned to a spatial point. 

Following this procedure, the X of the units are spatially random with no autocorrelation or spatial dependence. There is no unmeasured spatial confounding, conditional ignorability still holds. Interference is defined according to the spatial network structure, where each unit's outcome is dependent on its first-order neighbors' treatment. Further, non-stationarity can be introduced in several places, for example, in the determining function of Y, in the dependence between neighbors, or in the treatment propensity.

##  net1. 
Map data ns_1 to random network. 
```{r gen_nt, eval=FALSE}
n <- 5000
# generate net1 and map data_ns_1 to net1
# net1 <- sample_gnp(n,p=0.1,directed=FALSE,loops=FALSE) # non-spatial graph
net1<-igraph::sample_grg(n,radius=0.03,torus=FALSE,coords=TRUE) # spatial graph

plot(net1,vertex.size = 2,vertex.label = NA,
     axes=TRUE,margin=c(0,0,0,0),main="net1 structure")
hist(degree(net1)) # mostly between 5-20 first-order neighbours
# saveRDS(net1,file="net1_5k_structure.Rdata") 
```



```{r nt1_a, eval=FALSE}
# this is for the realistic case, where G will be guessed based on mean(Znei)

g1 <- igraph::as_data_frame(net1,what="vertices")# coords in (x, y)
colnames(g1)<-c("coordx","coordy")
g1$Z <- T_ns_1
g1$YZ <-Y_ns_1
g1$G <- 0
g1$YG <- 0
for (i in 1:n){
    neigh = igraph::neighbors(net1,v = i)
    g1$G[i] =  mean(g1$Z[neigh]) # mean exposure, can also use inverse dist w
    g1$YG[i] = mean(g1$YZ[neigh]) # neighborhood spillover YG
}
#hist(g1$YG)

# all POs. technically speaking this is a bit problematic...
YG1_nt_1<-g1$YG
YG0_nt_1<-0
YZ1_nt_1<-Y1_ns_1
YZ0_nt_1<-Y0_ns_1

Y00_nt_1<-YZ0_nt_1+YG0_nt_1
Y01_nt_1<-YZ0_nt_1+YG1_nt_1
Y10_nt_1<-YZ1_nt_1+YG0_nt_1
Y11_nt_1<-YZ1_nt_1+YG1_nt_1

# actual outcome
X_nt_1<-X_ns_1
A_adj<-as_adjacency_matrix(net1)
A<-as.matrix(A_adj)
Z_nt_1<-g1$Z
G_nt_1<-ifelse(g1$G >0.5, 1, 0)
T_nt_1<-paste0("t",Z_nt_1,G_nt_1)
g1$YG <- ifelse(g1$G >0.5, g1$YG, 0)
Y_nt_1<-g1$YZ+g1$YG 
#hist(YG1_nt_1)

# Compute gps later and check balance.
save(A_adj,Y00_nt_1,Y01_nt_1,Y10_nt_1,Y11_nt_1,Y_nt_1,X_nt_1,Z_nt_1,G_nt_1,T_nt_1,file="datanet1a_5k.Rdata")

# rethink:
# some issues remain in determining YG , and what is the true ps for G=1
# for each unit its neighborhood allocation is observed once, how to defined P(G=1|X)
# also, if G is determined by ps_g, how to infer G when only Z is observed.

# test prediction of Z and G
ps_est_nt_1z <-glm.fit(x=X_nt_1,y=Z_nt_1,family=binomial())
ps_est_nt_1z <-ps_est_nt_1z$fitted.values
X_nt_1g <- get_Xnei(X_nt_1,A,"adj")
ps_est_nt_1g <-glm.fit(x=X_nt_1g,y=G_nt_1,family=binomial())
ps_est_nt_1g <-ps_est_nt_1g$fitted.values

par(mfrow=c(2,1))
plot(ps_est_nt_1z,Z_nt_1,xlab="Z estimate",ylab="Z")
plot(ps_est_nt_1z,Z_nt_1,xlab="G estimate",ylab="G")
```


```{r nt1_b, eval=FALSE}
# this is for the diagnostic case where known ps_zg are fed into split cf to recover POs under interference.

# note: technically P(z=1,g=1)=Pz(z=1|Xz)*Pg(G=1|z=1,Xnei)*C.
# C=Pr(this specific combination of z & g, are actually paired)
# if X is spatially random, C is a constant. taking ratios of ps is not affected.
# if X is spatially patterned. C=f(X) is a function of X(pho,W,rand_x). ratios of ps should consider this dependence on spatial pattern of X.

# try determine G and/or YG differently
# Generally, it's not easy to estimate G=mean(Z[nei]) or YG =mean(YZ[nei]) with mean(X[nei]).
# but with nt_1 data, YZ and YG are just sums of X.

g1 <- igraph::as_data_frame(net1,what="vertices")# coords in (x, y)
colnames(g1)<-c("coordx","coordy")
g1$Z <- T_ns_1
g1$YZ <-Y_ns_1
g1$G <- 0
g1$YG <- 0

for (i in 1:n){
    neigh = igraph::neighbors(net1,v = i)
    g1$G[i] =  mean(g1$Z[neigh]) # mean exposure, can also use inverse dist w
    g1$YG[i] = mean(g1$YZ[neigh]) # neighborhood spillover YG
}
#hist(g1$YG)

# can try define G1 differently instead of using mean(Z[nei])
# g1$G1 <- gen_YG(Xnei,A)

# all POs. technically speaking this is a bit problematic...
YG1_nt_1<-g1$YG # basically = mean(Xnei) 
YG0_nt_1<-0
YZ1_nt_1<-Y1_ns_1 # mean(X)
YZ0_nt_1<-Y0_ns_1

Y00_nt_1<-YZ0_nt_1+YG0_nt_1
Y01_nt_1<-YZ0_nt_1+YG1_nt_1
Y10_nt_1<-YZ1_nt_1+YG0_nt_1
Y11_nt_1<-YZ1_nt_1+YG1_nt_1
# the definition of YG1 may be problematic. The functional between G=1 and YG1 is not clear. Maybe can define YG1 as a function of Xz? Xnei[,1]?
# or maybe define Y_zg directly based on the aggregate level of z and g, instead of using the spillover of YG (which is technically spillover the outcome, not spillover of treatment and should be discussed/ tested separately)

# propensities and realised outcome
A_adj<-as_adjacency_matrix(net1)
A<-as.matrix(A_adj)

Xnei_nt_1 <- get_Xnei(X_ns_1,A,"adj")
hist(Xnei_nt_1[,1]) 

ps_nt_1g <- pnorm(Xnei_nt_1[,1]) 
# plot(Xnei_nt_1[,1],ps_nt_1g,cex=.5)
ps_nt_1z <- ps_ns_1
ps_nt_1_11 <- ps_nt_1z*ps_nt_1g
ps_nt_1_10 <- ps_nt_1z*(1-ps_nt_1g)
ps_nt_1_01 <- (1-ps_nt_1z)*ps_nt_1g
ps_nt_1_00 <- (1-ps_nt_1z)*(1-ps_nt_1g)
ps_nt_1sum <- data.frame(t11=ps_nt_1_11,t10=ps_nt_1_10,t01=ps_nt_1_01,t00=ps_nt_1_00,
                         z=ps_nt_1z,g=ps_nt_1g)


G_nt_1 <- sapply(ps_nt_1g,function(x){rbinom(1,1,prob=x)})
g1$YG <- ifelse(G_nt_1==1, g1$YG, 0)
Y_nt_1<-g1$YZ+g1$YG 
#hist(YG1_nt_1)

# summarise and save data
X_nt_1<-X_ns_1
Z_nt_1<-g1$Z # Z_nt_1 <- sapply(ps_ns_1,function(x){rbinom(1,1,prob=x)})
T_nt_1<-paste0("t",Z_nt_1,G_nt_1)

# Compute gps later and check balance.
# save(A,ps_nt_1sum,Y00_nt_1,Y01_nt_1,Y10_nt_1,Y11_nt_1,Y_nt_1,X_nt_1,Z_nt_1,G_nt_1,T_nt_1,file="datanet1b_5k.Rdata")
```


```{r nt1_c, eval=FALSE}
# this is different from nt1_b in the generation of YG
# previoussly YG=mean(neighbors' YZ). This is in effect a spillover of outcome
# for spillover of treatment, strictly speaking, YG should be generated from the same mechanism producing GZ, just with added G level to the Z level.

# all POs.
YG1_nt_1<-0.5*Y1_ns_1 # same DGP of YZ: Y1_ns_1 = X_ns_1 %*% beta_ns_1 + rnorm(n)
YG0_nt_1<-0
YZ1_nt_1<-Y1_ns_1 # mean(X)
YZ0_nt_1<-Y0_ns_1

Y00_nt_1<-YZ0_nt_1+YG0_nt_1
Y01_nt_1<-YZ0_nt_1+YG1_nt_1
Y10_nt_1<-YZ1_nt_1+YG0_nt_1
Y11_nt_1<-YZ1_nt_1+YG1_nt_1
# the definition of YG1 may be problematic. The functional between G=1 and YG1 is not clear. Maybe can define YG1 as a function of Xz? Xnei[,1]?
# or maybe define Y_zg directly based on the aggregate level of z and g, instead of using the spillover of YG (which is technically spillover the outcome, not spillover of treatment and should be discussed/ tested separately)

# propensities and realised outcome
A_adj<-as_adjacency_matrix(net1)
A<-as.matrix(A_adj)

Xnei_nt_1 <- get_Xnei(X_ns_1,A,"adj")
#Xnei_mean <- mean(Xnei_nt_1)
#hist(Xnei_nt_1[,1]) 

ps_nt_1g <- pnorm(Xnei_nt_1[,1]) 
# plot(Xnei_nt_1[,1],ps_nt_1g,cex=.5)
ps_nt_1z <- ps_ns_1
ps_nt_1_11 <- ps_nt_1z*ps_nt_1g
ps_nt_1_10 <- ps_nt_1z*(1-ps_nt_1g)
ps_nt_1_01 <- (1-ps_nt_1z)*ps_nt_1g
ps_nt_1_00 <- (1-ps_nt_1z)*(1-ps_nt_1g)
ps_nt_1sum <- data.frame(t11=ps_nt_1_11,t10=ps_nt_1_10,t01=ps_nt_1_01,t00=ps_nt_1_00,
                         z=ps_nt_1z,g=ps_nt_1g)


G_nt_1 <- sapply(ps_nt_1g,function(x){rbinom(1,1,prob=x)})
YG_nt_1 <- ifelse(G_nt_1==1,YG1_nt_1, 0)
Y_nt_1<-Y_ns_1+YG_nt_1 
#hist(YG1_nt_1)

# summarise and save data
X_nt_1<-X_ns_1
Z_nt_1<-T_ns_1 # Z_nt_1 <- sapply(ps_ns_1,function(x){rbinom(1,1,prob=x)})
T_nt_1<-paste0("t",Z_nt_1,G_nt_1)

# save(A,ps_nt_1sum,Y00_nt_1,Y01_nt_1,Y10_nt_1,Y11_nt_1,Y_nt_1,X_nt_1,Z_nt_1,G_nt_1,T_nt_1,file="datanet1b_5k.Rdata")
```


##  net2. 
Map data ns_2 to same random network as net1.
nt_2 data is used for test 7.
```{r nt2, eval=FALSE}
# map data_ns_2 to net1, with updated Z, G, YZ, YG, Y
g2<-g1
g2$Z <- T_ns_2
g2$YZ <-Y_ns_2
g2$G <- 0
g2$YG <- 0
for (i in 1:n){
    neigh = igraph::neighbors(net1,v = i)
    g2$G[i] =  mean(g2$Z[neigh]) 
    g2$YG[i] =0.2*mean(g2$YZ[neigh]) 
}
# all POs.
YG1_nt_2<-g2$YG
YG0_nt_2<-0 # 0 or white noise?
YZ1_nt_2<-Y1_ns_2
YZ0_nt_2<-Y0_ns_2

Y00_nt_2<-YZ0_nt_2+YG0_nt_2
Y01_nt_2<-YZ0_nt_2+YG1_nt_2
Y10_nt_2<-YZ1_nt_2+YG0_nt_2
Y11_nt_2<-YZ1_nt_2+YG1_nt_2

# actual outcome
Xnei_nt_2 <- get_Xnei(X_ns_2,A,"adj")
ps_nt_2g <- pnorm(Xnei_nt_2[,1]) # hist(ps_nt_1g)
ps_nt_2z <- ps_ns_2
ps_nt_2_11 <- ps_nt_2z*ps_nt_2g
ps_nt_2_10 <- ps_nt_2z*(1-ps_nt_2g)
ps_nt_2_01 <- (1-ps_nt_2z)*ps_nt_2g
ps_nt_2_00 <- (1-ps_nt_2z)*(1-ps_nt_2g)

G_nt_2 <- sapply(ps_nt_2g,function(x){rbinom(1,1,prob=x)})
g2$YG <- ifelse(G_nt_2==1, g2$YG, 0)
Y_nt_2<-g2$YZ+g2$YG 

X_nt_2<-X_ns_2
# A_adj 
Z_nt_2<-g2$Z
T_nt_2<-paste0("t",Z_nt_2,G_nt_2)
save(ps_nt_2g,ps_nt_2z,Y00_nt_2,Y01_nt_2,Y10_nt_2,Y11_nt_2,Y_nt_2,X_nt_2,Z_nt_2,G_nt_2,T_nt_2,file="datanet2_5k.Rdata")
```


## net3. 
From nt_2, add spatial non-stationarity in y=f_beta(x) to net2 outcome YZ.

nt_3 data is used for test 10. It is expected that local estimates will be better than global estimtes. The latter will still gain good coverage but the intervals will be wide due to the unmeasured spatial heterogeneity in the errors.

```{r nt3, eval=FALSE}
set.seed(123)
# outcome Y_i(Z=1) is dependent on location of i ,
# in the form of spatially varying coeff in generating Y(Z=1)
grid <- expand.grid(1:100, 1:100)
names(grid)<-c("x","y")

# spatial trend
g.dummy1 <- gstat(formula=z~1+x+y, locations=~x+y, dummy=T, beta=c(1,0.01,0.005), model=vgm(psill=0.025, range=15, model='Exp'), nmax=20)
# random clustering
g.dummy2 <- gstat(formula=z~1, locations=~x+y, dummy=T, beta=c(1,0.01,0.005), model=vgm(psill=0.025, range=15, model='Exp'), nmax=20)

coeff_grid <- predict(g.dummy1, newdata=grid, nsim=4)
sp::gridded(coeff_grid) = ~x+y
# saveRDS(coeff_grid,file="coeff_grid.Rdata") 
# spplot(coeff_grid)
sim<-data.frame(coeff_grid$sim1,coeff_grid$sim2,coeff_grid@coords)
colnames(sim)<-c("coeff1","coeff2","x","y")
sim$xy<-paste0(sim$x,"-",sim$y)

coeff<-data.frame(floor(g1$coordx*100)+1,floor(g1$coordy*100)+1)
colnames(coeff)<-c("x","y")
coeff$xy<-paste0(coeff$x,"-",coeff$y)
coeff<-left_join(coeff,sim[,c(1,2,5)],by="xy")

genY_nt_3 <- function(X){
  2 / (1 + exp(coeff$coeff1*(X[, 1]-0.5)))*2/(1 + exp(-1 *(X[, 2] - 0.5)))+rnorm(n)
}
YZ1_nt_3 <- genY_nt_3(X_ns_2) 
# length(YZ1_nt_3)
# hist(Y1_nt_3)
# plot(X_ns_2[,1],Y1_nt_3)
YZ_nt_3 <- ifelse(T_ns_2 == 1, YZ1_nt_3, Y0_ns_2)
# copy net1, with updated YZ, YG, Y
g3<-g1
g3$YZ <-YZ_nt_3
for (i in 1:n){
    neigh = igraph::neighbors(net1,v = i)
    g3$YG[i] =0.2*mean(g3$YZ[neigh])
}
# all POs.
YG1_nt_3<-g3$YG
YG0_nt_3<-0
#YZ1_nt_3
YZ0_nt_3<-Y0_ns_2

Y00_nt_3<-YZ0_nt_3+YG0_nt_3
Y01_nt_3<-YZ0_nt_3+YG1_nt_3
Y10_nt_3<-YZ1_nt_3+YG0_nt_3
Y11_nt_3<-YZ1_nt_3+YG1_nt_3

# actual outcome
g3$YG <- ifelse(g3$G >0.5, g3$YG, 0)

Y_nt_3<-g3$YZ+g3$YG
X_nt_3<-X_ns_2
# A_adj
Z_nt_3<-g3$Z
G_nt_3<-ifelse(g3$G >0.5, 1, 0)
T_nt_3<-paste0("t",Z_nt_3,G_nt_3)
save(Y00_nt_3,Y01_nt_3,Y10_nt_3,Y11_nt_3,Y_nt_3,X_nt_3,Z_nt_3,G_nt_3,T_nt_3,file="datanet3_5k.Rdata")
```

```{r net3_plots, eval=FALSE}
# the spatial fields
spplot(coeff_grid)

# X, Y, Z and G
# mapcheck<-cbind.data.frame(x=coeff$x,y=coeff$y,X_ns_1,Z_nt_3,G_nt_3,Y_nt_3)
ggplot(mapcheck,aes(x=x,y=y,color=`1`))+geom_point(size=2)+scale_colour_gradient2()
ggplot(mapcheck,aes(x=x,y=y,color=Y_nt_3))+geom_point(size=2)+scale_colour_gradient2()
ggplot(mapcheck,aes(x=x,y=y,color=Z_nt_3))+geom_point(size=2)+scale_colour_gradient2()
ggplot(mapcheck,aes(x=x,y=y,color=G_nt_3))+geom_point(size=2)+scale_colour_gradient2()
ggplot(coeff,aes(x=x,y=y,color=coeff1))+geom_point(size=2)+scale_colour_gradient2()

```

## net4. With network autocorrelation. This may affect the design of conformal prediction (As long as sampling is random, exchangeability still approximately holds. If there's a spatial pattern in Y, modeling it may help increase outcome prediction accuracy in the face of unmeasured spatial confounding ). Otherwise it should not make a difference for causal identification, since we assume conditional ignorability.
 nt_4 data is used for tests 8 and 9. In test 8 all X generating autocorrelation is controlled for. In test9 only some X are controlled for, simulating a scenario with unmeasured spatial confounding.

Spatial autocorrelation in X1 X2 generated by SAR process. (on top of ns_2)
```{r nt4, eval=FALSE}
set.seed(123)
n <- 5000
d <- 5
rho<- 0.8

X_nt_4 <- X_ns_2 # non-linear
# generate autocorr in X1 X2 by smoothing X with rho*Xnei 
Xnei_nt_4 <- get_Xnei(X_nt_4,A,"adj")
hist(0.5*X_nt_4[,1]+Xnei_nt_4[,1]) # X is unif, Xnei is Gaussian 

X_nt_4[,1]<- 0.5*X_nt_4[,1]+Xnei_nt_4[,1]
X_nt_4[,2]<- 0.5*X_nt_4[,1]+Xnei_nt_4[,2] 

#X_nt_4[,1]<-Xnei_nt_4[,1]
#X_nt_4[,2]<-Xnei_nt_4[,2] 

# Gen Y
genY_nt_4 <- function(X){
  (2 / (1+exp(-12*(X[, 1]-0.5))))*(2/(1+exp(-12*(X[, 2]-0.5))))+X[, 3]+rnorm(n)
  }
YZ1_nt_4 <- genY_nt_4(X_nt_4)
YZ0_nt_4 <- rnorm(n)
# hist(YZ1_nt_4)
plot(X_nt_4[, 1],YZ1_nt_4,cex=.5) # if just use Xnei as X, no longer corr with Y ?

ps_nt_4z <- pnorm(X_nt_4[, 1]+X_nt_4[, 2])
# hist(ps_nt_4z)
# corr in psz induced by X1 and X2. in test8 both adjusted for, in test9 only X2.
# does it matter whether ps is generated from a sp autocorr X ???
Z_nt_4 <- sapply(ps_nt_4z,function(x){rbinom(1,1,prob=x)})
YZ_nt_4 <- ifelse(Z_nt_4==1, YZ1_nt_4, YZ0_nt_4)

# map data to net1, with updated Z, G, YZ, YG, Y
g4<-g1
g4$Z <- Z_nt_4
g4$YZ <-YZ_nt_4
g4$G <- 0
g4$YG <- 0
for (i in 1:n){
    neigh = igraph::neighbors(net1,v = i)
    g4$G[i] =  mean(g4$Z[neigh]) 
    g4$YG[i] =0.5*mean(g4$YZ[neigh]) 
}
# all POs. 
# from here, it's clear that YG is conditional on the observed YZ i.e. the pattern of YZ
YG1_nt_4<-g4$YG
YG0_nt_4<-0 

Y00_nt_4<-YZ0_nt_4+YG0_nt_4
Y01_nt_4<-YZ0_nt_4+YG1_nt_4
Y10_nt_4<-YZ1_nt_4+YG0_nt_4
Y11_nt_4<-YZ1_nt_4+YG1_nt_4

# actual outcome
Xnei_nt_4g <- get_Xnei(X_nt_4,A,"adj")
ps_nt_4g <- pnorm(Xnei_nt_4g[,1]) # closely centered around 0.5
# ps_nt_4g <- ifelse(g4$G >0.5, 1, 0) # alternatively G determined by Z_nei cutoff
# hist(Xnei_nt_4g[,1])
# hist(ps_nt_4g) 
G_nt_4 <- sapply(ps_nt_4g,function(x){rbinom(1,1,prob=x)})
g4$YG <- ifelse(G_nt_4==1, g4$YG, 0)
Y_nt_4<-g4$YZ+g4$YG 
T_nt_4<-paste0("t",Z_nt_4,G_nt_4)

# plotting
mapcheck2<-cbind.data.frame(x=coeff$x,y=coeff$y,Xnei_nt_4,X_nt_4)
ggplot(mapcheck,aes(x=x,y=y,color=`1`))+geom_point(size=2)+scale_colour_gradient2()
ggplot(mapcheck2,aes(x=x,y=y,color=`V1`))+geom_point(size=2)+scale_colour_gradient2()
ggplot(mapcheck2,aes(x=x,y=y,color=`1`))+geom_point(size=2)+scale_colour_gradient2()

save(ps_nt_4g,ps_nt_4z,Y00_nt_4,Y01_nt_4,Y10_nt_4,Y11_nt_4,Y_nt_4,X_nt_4,Z_nt_4,G_nt_4,T_nt_4,file="datanet4_5k.Rdata")

```


```{r nt4b, eval=FALSE}

```


# testing the estimation of GPS

```{r testid, eval=FALSE}

testid0<- sample(n,1) # 694
```


```{r test1, eval=FALSE}
# binary treatment, 4 level exposure, getting GPS and test balance
A<-as.matrix(A_adj)

# glm predictions
test1_gps1 <- get_gps1(tr = Z_nt_1,covar = X_nt_1,A = A,Atype="adj",
                    pstype="joint",ps_pred_model="binomial")

# check estimate of ps for Z and G
par(mfrow=c(1,2))
plot(ps_nt_1z,test1_gps1[,5],xlab="ps_Z",ylab="ps_Z estimate",cex=.3)
plot(ps_nt_1g,test1_gps1[,6],xlab="ps_G",ylab="ps_G estimate",cex=.3)

par(mfrow=c(2,2))
plot(ps_nt_1_11,test1_gps1[,1],xlab="ps_11",ylab="ps_11 estimate",cex=.3)
plot(ps_nt_1_10,test1_gps1[,2],xlab="ps_10",ylab="ps_10 estimate",cex=.3)
plot(ps_nt_1_01,test1_gps1[,3],xlab="ps_01",ylab="ps_01 estimate",cex=.3)
plot(ps_nt_1_00,test1_gps1[,4],xlab="ps_00",ylab="ps_00 estimate",cex=.3)

par(mfrow=c(2,1))
plot(test1_gps1[,5],Z_nt_1)
plot(test1_gps1[,6],G_nt_1)

hist(test1_gps1[,1]) # why this shape?

```

```{r test1b, eval=FALSE}
# nnet::multinom predictions
test1_gps2 <- get_gps1(tr = Z_nt_1,covar = X_nt_1,A = A,Atype="adj",
                    pstype="joint",ps_pred_model="multinom")
test1_gps2 <- as.data.frame(test1_gps2)
test1_gps2$z<-test1_gps2[,1]+test1_gps2[,2]
test1_gps2$g<-test1_gps2[,1]+test1_gps2[,3]

par(mfrow=c(2,1))
plot(test1_gps2$z,Z_nt_1,xlab="Z estimate",ylab="Z")
plot(test1_gps2$g,G_nt_1,xlab="G estimate",ylab="G")

par(mfrow=c(2,2))
plot(test1_gps1[,1],test1_gps2[,1],xlab="T11 binom est",ylab="T11 mult est")
plot(test1_gps1[,2],test1_gps2[,2],xlab="T10 binom est",ylab="T10 mult est")
plot(test1_gps1[,3],test1_gps2[,3],xlab="T01 binom est",ylab="T01 mult est")
plot(test1_gps1[,4],test1_gps2[,4],xlab="T00 binom est",ylab="T00 mult est")


#check<-data.frame(T_nt_1,test1_gps3) # T predictions only 50% accurate

```

```{r test1c, eval=FALSE}
# boosting 
# similar problem as others
# gbm.predict 
# type="response" returns probabilities for binomial and counts for poisson
# type="link" return log odds for binomial

```


# Testing spatial conformal for interference

## compute spatial PO (with interference) coverage, with estimated ps
This section will be reported.
For computing coverage, experiments are rerun 100 times. 
test6 (_nt_1 spatial linear) 
test7 (_nt_2 spatial non-linear) 

test8 (_nt_4 spatial confounding in autoregressive X fully controlled for)
test9 (_nt_5 unmeasured spatial confounding)

test10 (_nt_3 spatial non-stationary and local estimates).

```{r test_Ymodel, eval=FALSE}
# test Ymodel predictions
# use X_nt_1 Xnei to predict Y

X11<-X_nt_1[which(T_nt_1=="t11"),,drop=FALSE]
Xnei11<- get_Xnei(X_nt_1,A,"adj")
Xnei11<-Xnei11[which(T_nt_1=="t11"),,drop=FALSE]
X11<-cbind.data.frame(X11,Xnei11)
Y11<-Y_nt_1[which(T_nt_1=="t11")]
length(Y11) # 1295
fit11<-grf::quantile_forest(X = X11[1:1200,], Y = Y11[1:1200],quantiles = c(0.05,0.95))
Y11_hat <- predict(fit11, X11[1200:1295,],quantiles = c(0.05,0.95))
Y11_hat <- Y11_hat$predictions
Y11test <- Y11[1200:1295]
cov <- abs(Y11_hat[,2]-Y11_hat[,1]) - pmax(abs(Y11test-Y11_hat[,1]),
                                            abs(Y11test-Y11_hat[,2]))
length(which(cov>0))/length(cov)
# 96.9% Ymodel is OK

```


Alternative test6 spatial PO (with interference) coverage, with ps known exactly 
This is not a realistic scenario, because normally only Z is observed and G can only be inferred and therefore ps_g always a lousy estimation.
Never the less, providing the exact ps_z and ps_g helps diagnose whether model performance is critically hinging on a good estimate of ps_g.
COverage is actually 0.7 and smaller than test6. why?


## summary of coverage
```{r cal_coverage, eval=FALSE}
# repeated experiments to calculate coverage
# PO_true is a dataframe of true POs Y11, Y10, Y01, Y00
# return PO coverage rates and lengths of ITE prediction intervals
cal_coverage <- function(X,Y,testid,tr,A,Atype,
                         ps_pred_model,ps,G,
                         outfun,CQR,retrainYmodel,
                         iter=30,PO_true){

  cov1<-cov2<-cov3<-cov4<-len1<-len2<-len3<-len4<-c()
  
  for (i in 1:iter){
    temp <- conformal_ITE1(X=X, Y=Y, testid=testid,tr=tr,
                              A=A,Atype=Atype,
                              ps_pred_model=ps_pred_model,
                              ps=ps, G=G,outfun=outfun, CQR=CQR,
                              retrainYmodel=retrainYmodel)
    c1 <- abs(temp[[1]][,2]-temp[[1]][,1]) - pmax(abs(PO_true[,1]-temp[[1]][,1]),
                                            abs(PO_true[,1]-temp[[1]][,2]))
    c2 <- abs(temp[[1]][,4]-temp[[1]][,3]) - pmax(abs(PO_true[,2]-temp[[1]][,3]),
                                            abs(PO_true[,2]-temp[[1]][,4]))
    c3 <- abs(temp[[1]][,6]-temp[[1]][,5]) - pmax(abs(PO_true[,3]-temp[[1]][,5]),
                                            abs(PO_true[,3]-temp[[1]][,6]))
    c4 <- abs(temp[[1]][,8]-temp[[1]][,7]) - pmax(abs(PO_true[,4]-temp[[1]][,7]),
                                            abs(PO_true[,4]-temp[[1]][,8]))
    cov1[i] <-length(which(c1>0))/length(c1)
    cov2[i] <-length(which(c2>0))/length(c2)
    cov3[i] <-length(which(c3>0))/length(c3)
    cov4[i] <-length(which(c4>0))/length(c4)
    len1[i] <-mean(temp[[2]][,2]-temp[[2]][,1])
    len2[i] <-mean(temp[[2]][,4]-temp[[2]][,3])
    len3[i] <-mean(temp[[2]][,6]-temp[[2]][,5])
    len4[i] <-mean(temp[[2]][,8]-temp[[2]][,7])
  }
  cov<-data.frame(cov11=cov1,cov10=cov2,cov01=cov3,cov00=cov4,
                 len11=len1,len10=len2,len01=len3,len00=len4)
  return(cov)
}
```


```{r test6_cov}

testid6 <- sample(5000,50) # n=30, run time: QRF 14/ 90s , QBART 110s
# test6
# # input X_nt_1, Y_nt_1, Z_nt_1, Y11_nt_1, Y10_nt_1, Y01_nt_1, Y00_nt_1
# either the Ymodel is only fitted once and a list of testid are fed to the model, 
# or the Ymodel is fitted again each time a new test point is supplied.
# TO do: ! atm use retrainYmodel=TRUE, so that the order of outputs will not be scrambled.
# test 62
# input X_nt_1, Y_nt_1, Z_nt_1, Y11_nt_1, Y10_nt_1, Y01_nt_1, Y00_nt_1, ps_nt_1sum
# weighted split conformal under interference with known ps and known G
# use dataset nt1_b / nt1_c which regenerates X Y Z
# optional: true ps in ps_nt_1sum, true G in G_nt_1
test6_Y <- data.frame(Y11=Y11_nt_1[testid6],
                      Y10=Y10_nt_1[testid6],
                      Y01=Y01_nt_1[testid6],
                      Y00=Y00_nt_1[testid6])
test6_cov <- cal_coverage(X=X_nt_1, Y=Y_nt_1, 
                              testid=testid6,
                              tr=Z_nt_1,
                              A=A,Atype="adj",
                              ps_pred_model="multinom",
                              ps=NA, G=NA,
                              outfun="QRF", CQR=TRUE,
                              retrainYmodel=TRUE,
                         iter=30,PO_true=test6_Y)

# test7 
# input X_nt_2, Y_nt_2, Z_nt_2, Y11_nt_2, Y10_nt_2, Y01_nt_2, Y00_nt_2
# uses same testid6
test7_Y <- data.frame(Y11=Y11_nt_2[testid6],
                      Y10=Y10_nt_2[testid6],
                      Y01=Y01_nt_2[testid6],
                      Y00=Y00_nt_2[testid6])
test7_cov <- cal_coverage(X=X_nt_1, Y=Y_nt_1, 
                              testid=testid6,
                              tr=Z_nt_1,
                              A=A,Atype="adj",
                              ps_pred_model="multinom",
                              ps=NA, G=NA,
                              outfun="QRF", CQR=TRUE,
                              retrainYmodel=TRUE,
                         iter=30,PO_true=test7_Y)

# test8 
# input X_nt_4, Y_nt_4, Z_nt_4, Y11_nt_4, Y10_nt_4, Y01_nt_4, Y00_nt_4
test8_Y <- data.frame(Y11=Y11_nt_4[testid6],
                      Y10=Y10_nt_4[testid6],
                      Y01=Y01_nt_4[testid6],
                      Y00=Y00_nt_4[testid6])
test8_cov <- cal_coverage(X=X_nt_4, Y=Y_nt_4, 
                              testid=testid6,
                              tr=Z_nt_4,
                              A=A,Atype="adj",
                              ps_pred_model="multinom",
                              ps=NA, G=NA,
                              outfun="QRF", CQR=TRUE,
                              retrainYmodel=TRUE,
                         iter=30,PO_true=test7_Y)
# test9 
# input X_nt_5=X_nt_4[,2:5], Y_nt_4, Z_nt_4, Y11_nt_4, Y10_nt_4, Y01_nt_4, Y00_nt_4
test9_Y <- test8_Y
X_nt_5<-X_nt_4[,2:5]
test9_cov <- cal_coverage(X=X_nt_5, Y=Y_nt_4, 
                              testid=testid6,
                              tr=Z_nt_4,
                              A=A,Atype="adj",
                              ps_pred_model="multinom",
                              ps=NA, G=NA,
                              outfun="QRF", CQR=TRUE,
                              retrainYmodel=TRUE,
                         iter=30,PO_true=test7_Y)

# test10 global. use conformal_ITE1()
# input X_nt_2, Y_nt_2, Z_nt_2, Y11_nt_2, Y10_nt_2, Y01_nt_2, Y00_nt_2
# uses same testid6
test10_Y <- data.frame(Y11=Y11_nt_3[testid6],
                      Y10=Y10_nt_3[testid6],
                      Y01=Y01_nt_3[testid6],
                      Y00=Y00_nt_3[testid6])
test10_global_cov <- cal_coverage(X=X_nt_3, Y=Y_nt_3, 
                              testid=testid6,
                              tr=Z_nt_3,
                              A=A,Atype="adj",
                              ps_pred_model="multinom",
                              ps=NA, G=NA,
                              outfun="QRF", CQR=TRUE,
                              retrainYmodel=TRUE,
                         iter=30,PO_true=test7_Y)
test10_local_cov
```

```{r plot_coverage}
cov=rnorm(600,90)
Tr0=rep(c("11","10","01","00"),each=30)
Tr=c(Tr0,Tr0,Tr0,Tr0,Tr0)
test=rep(c("test6","test7","test8","test9","test10"),each=120)
testplot<-data.frame(cov,Tr,test)

par(mar=c(3,4,3,1))
boxplot(cov~Tr*test,data=testplot,boxwex=0.4,ylab="coverage %",
        main="Coverage of potential outcomes",
        col=c("slateblue1","lightblue","pink","tomato"),
        xaxt="n")
axis(1,at=seq(2.5,22,4),labels=c("test6","test7","test8","test9","test10"),tick=FALSE,cex=0.3)
for(i in seq(0.5 , 20 , 4)){ 
  abline(v=i,lty=1, col="grey")
}
legend("bottomright", legend = c("t11","t10","t01","t00"), 
       col=c("slateblue1","lightblue","pink","tomato"),
       pch = 15, bty = "n", pt.cex = 2, cex = 1,  horiz = T, inset = c(0, 0))
```

