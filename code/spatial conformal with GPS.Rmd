---
title: "sp conformal with gps"
author: "mira"
date: "2022/6/12"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


```{r}
library(tidyverse)
library(ggplot2)
library(viridis)
library(argparse)
library(grf)
library(gbm)
library(randomForest)
library(bartMachine)
library(igraph)
#library(SuperLearner)
library(xgboost)
library(MASS)
library(nnet)
#library(causalToolbox)

```

# Intro
Why spatial interference.

Why ITE in favor of ATE CATE CQTE: Better account for treatment effect heterogeneity (which could result from spatial process).

Why intervals instead of point estimate: Uncertainty quantification for sensitive decision making. Better coverage.

Why conformal prediction: Non-parametric. Flexible. Accommodates various prediction models.

How to handle non-exchangeability in spatial conformal prediction: Assume ‘local’ exchangeability, using distance kernel to restrict scope of training data points. Or use global spatial CV technique.

How to handle spatial interference: In the case of non-trivial spatial interference, treatment effect defined as total effect, direct and spillover effect. For estimation, introduce generalised propensity score (gps), which defines treatment probability as a function of ego and neighbouring units’ covariates. The gps restores the ignorability and SUTVA assumptions underpinning classic PO framework. Besides individual level covariates, network and neighbourhood properties (such as centrality metrics or local averages) can also be included (Forastiere et.al., 2021). Network uncertainty can also be incorporated (may or may not have time for this in this project).

Relation to prior work: Extension and synthesis of prior work to spatial interference (Forastiere), bringing together conformal counterfactual prediction (Barber, Candes, Lei) and gps (Hirano & Imbens) based techniques.



# The proposed routine of analysis

## Get propensity scores for spatial interference

### Interference and definitions of causal effects
With interference, there can be multiple levels of exposure to unit $i$ even for binary treatments. That is, the actual exposure level is a function of the unit's treatment $Z_{i}$ and others' treatment program $G_{i}$. The generalised propensity score $e(x,g)$ (Hirano & Imbens, 2004) has been developed for these scenarios (Forastiere et.al., 2021). Exposure level can be treated as either continuous or discretised. Here, for simplicity, we start with four levels of treatment,  $(Z_{i}=0,G_{i}=0)$ , $(Z_{i}=0,G_{i}=1)$ , $(Z_{i}=1,G_{i}=0)$ , $(Z_{i}=1,G_{i}=1)$. Treatment $G_{i}$ is defined as a function of the proportion of unit i's neighbours getting treatment. (Forastiere originally proposed to work with many strata of treatment levels.)

### The joint propensity score and its properties 
The bivariate treatment to a unit and its neighbors is a joint treatment. The joint propensity score is the probability of assignment to a particular individual and neighborhood treatment given the observed covariates. The covariates to predict the propensity score can include individual level attributes of unit $i$, as well as neighborhood level aggregate attributes and spatial network structural properties.  

The joint score can be factorised: $e(z,g,x)=P(Z_{i}=z,G_{i}=g|X_{i}=x)=P(Z_{i}=z|G_{i}=g,X_{i}^z=x^z)P(G_{i}=g|X_{i}^g=x^g)$ The factorised form is easier to work with, especially if we assume $Z_{i}$  is conditional independent of $G_{-i}$, that is, individual treatment assignments are determined by covariates indepedently. Unconfoundedness holds not only conditional on the joint propensity score but also conditional on the individual and neighborhood propensity scores. This gives an unbiased estimator for the average dose response function with both individual and neighbor propensity scores being adjusted for $E[E[Y_{i}|Z_{i}=z,G_{i}=g,\phi(X_{i}^z),\lambda(g,z,X_{i}^g)]|Z_{i}=z,G_{i}=g]$. The individual ps can be obtained with standard binary treatment ps methods. The neighborhood ps requires generalised ps methods, since $G_{i}$ is not binary. Still, the question remains, how do we define the influencing 'neighborhood' of a unit? In fact, is it possible at all to define it without referencing the observed outcomes (i.e. exogenously)???


ref:  
https://github.com/cran/CausalGPS/blob/master/R/estimate_gps.R
https://github.com/cran/twangRDC/blob/master/R/ps.xgb.r

```{r get_gps, include=TRUE, eval=FALSE}
# the psfun
# input
# tr          col vector of individual level binary treatments, numeric
# covar       dataframe/matrix of covariates
# A           spatial network, adjacency matrix or distance matrix 
# Atype       type of A, "dist" or "adj", A does not have to be symmetric
# pstype      "joint" e(x)=P(Z=1,G=g|X=x), 
#             "conditional" e(x,g)=P(Z=1|G=g,X=x) take the product of P(G=g|X=x) or not...
# pred_model  "xgboost" or "multinom" or "binom" (binom for conditional ps only)
# output
# ps          propensity scores

get_gps <- function(tr,
                    covar,
                    A,
                    Atype="dist",
                    pstype="conditional",
                    pred_model="binomial"){
  # check args insert code here
  
  # format treatment and covariates
  n<-length(tr)
  
  if (Atype=="dist") {
    # define treatment levels tl based on tr and A, stratified to 4 treatment levels
    A0 <- A
    diag(A0) <-1
    A0 <- A^(-1)
    diag(A0) <- 0
    A0 <- A0/rowSums(A0) # row std inverse dist, can try other dist decay func
    trnei <- rowSums(replicate(n,tr)*A0) # neighbor treatment level [0,1]
    trnei <- ifelse(trnei>0.5,1,0) # neighbor treatment {0,1}, 0.5 is arbitrary here
    tl <- paste0(tr,trnei) # treatment level, multinomial
    # alternatively tl can be ordinal/continuous, can be a vec of length 2 not sure how it works yet...
    
    # construct neighborhood covariates, the average of neighbors
    k <- ncol(covar) # num of covariates
    covnei <- list()
     for i in (1:k) {
      covnei[[i]] <- rowSums(replicate(n,covar[,i])*A0)
    }
    covnei <- as.data.frame(do.call(cbind,covnei))
    covar0 <- cbind.data.frame(covar,covnei)
  }
  
  if (Atype=="adj") {
    # the adjacency matrix can be simply geo contiguity or otherwise defined
    # assume A is unweighted (if directed, j should be in the row names)
    # define treatment levels tl
    A0 <- A
    A0 <- A0/rowSums(A0) # row std 
    trnei <- rowSums(replicate(n,tr)*A0)
    trnei <- ifelse(trnei>0.5,1,0)
    tl <- paste0(tr,trnei)
    
    # construct neighborhood covariates, neighborhood means and network properties
    k <- ncol(covar)
    covnei <- list()
    for i in (1:k) {
      covnei[[i]] <- rowSums(replicate(n,covar[,i])*A0)
    }
    covnei <- as.data.frame(do.call(cbind,covnei))
    netA <- igraph::graph_from_adjacency_matrix(A,mode="undirected",weighted=FALSE)
    btwnss <- betweenness(netA, weights = NA) # can try other metrics
    covar0 <- cbind.data.frame(covar,covnei,btwnss)
  }
 
   
  # fit treatment model and estimate propensity scores
  if (pstype=="joint"){
    if (pred_model=="multinom"){
         pred0 <- nnet::multinom(x=covar0,y=tl)
         # insert code here
    }
    if (pred_model=="xgboost"){
         pred0 <- xgboost::xgboost(data=covar0,label=tl) # data in matrix 
         # insert code here
    }
    if (pred_model=="binom"){stop('Joint ps cannot be estimated with binomial model.')}
  }
  
  if (pstype=="conditional"){
    # by default use pred_model=="binom"
    # tr numeric
    data0=cbind.data.frame(covar0,trnei)
    if (pred_model=="xgboost"){
         pred0 <- xgboost::xgboost(data=data0,label=tr) 
         ps <- as.matrix(predict(pred0,newdata=data0))
    }
    else{
         pred0 <- glm.fit(x=data0,y=tr,family="binomial")
         std <- pred0$sigma 
         pred <- pred0$fitted.values
         ps <- dnorm(tr,mean=pred,sd=std) 
    }    
  }
  
  # return the estimated propensity score
  return(ps)
}
```


## Introduce GPS to weighted conformal prediction to obtain counterfactuals. 

The generalised propensity restores the ignorability and SUTVA assumptions underpinning classic PO framework. In the case of non-trivial spatial interference, we try to estimate the total effect $Y_{i}(Z_{i}=1,G_{-i}=1)-Y_{i}(Z_{i}=0,G_{-i}=0)$ , direct effect $Y_{i}(Z_{i}=1,G_{-i}=0)-Y_{i}(Z_{i}=0,G_{-i}=0)$ and spillover effect $Y_{i}(Z_{i}=0,G_{-i}=1)-Y_{i}(Z_{i}=0,G_{-i}=0)$.

ref: 
Lei, L. & Candes, E. (2021) Conformal Inference of Counterfactuals and Individual Treatment Effects. arXiv:2006.06138v2 


```{r utils, include=FALSE, eval=FALSE}
source("utils.R", local = knitr::knit_global())
#  imports conformalScore, gen_cv_ids, weightedConformalCutoff, RF, quantRF, Boosting
```

### generic split conformal 
Using CV is more efficient. For each of the folds, the generic split conformal procedure defined above is carried out. Here we use the split conformal.
```{r}

# X, Y
# outfun
# outparams (if CQR quantiles should be part of outparams, not necessary for mean estimation)
# wtfun
# alpha
# trainprop
# trainid
# Xtest testing covariates.
# output prediction interval

conformalSplit <- functon(X, Y, Xtest,
                           outfun, outparams,
                           wtfun,
                           alpha=0.1,
                           trainprop=0.6, trainid){
  # type="mean"
  # side=two sided
  # null is equal weights
  if (is.null(wtfun)){ wtfun <- function(X){ rep(1, nrow(X))}}
  
  # subset training data and val data
  n <- length(Y)
  if (is.null(trainid)){trainid <- sample(n, floor(n * trainprop))}
  Xtrain <- X[trainid, ,drop=FALSE]
  Ytrain <- Y[trainid]
  Xval <- X[-trainid, ,drop=FALSE]
  Yval <- Y[-trainid]
  # prep outfun
  outparams <- c(list(Y = Ytrain, X = Xtrain), outparams)
  Ymodel <- function(X){do.call(outfun, c(outparams, list(Xtest = X)))}
  # get Yhat mean estimate of Yval and residuals
  Yhat <- Ymodel(Xval)
  Yscore <- conformalScore(Yval, Yhat)
  wt <- wtfun(Xval)
  # get Yhat_test mean estimate of the targets Ytest
  Yhat_test <- Ymodel(Xtest)
  wt_test <- wtfun(Xtest)
  # prep weights
  avg_wt <- mean(c(wt, wt_test))
  wthigh <- 20 
  wtlow <- 0.05
  wt <- censoring(wt/avg_wt, wthigh, wtlow)
  wt_test <- censoring(wt_test/avg_wt, wthigh, wtlow)
  totw <- sum(wt)
  wt <- wt / totw
  # get Yslack
  qt <- (1 + wt_test / totw) * (1 - alpha) # quantile 1-alpha
  qt <- pmin(qt, 1) # cap quantile at 1
  Yslack <- weightedConformalCutoff(Yscore, wt, qt) # find score(residual) at given qt
  # from mean estimate to intervals
  Ylo <- Yhat_test - Yslack
  Yup <- Yhat_test + Yslack
  # output prediction interval
  out <- data.frame(lower = Ylo, upper = Yup)
  return(out)
}

```


### counterfactual prediction with weighted split conformal

Counterfactual conformal prediction is similar to generic conformal prediction. It is an application of weighted confomal prediction (Tibshirani, 2019).  The main feature of counterfactual conformal prediction is the introduction of propensity scores e(x) for the weighting. The weights in IPW estimators are essentially calibrating the observed covariate distribution to the target one. This is similar in spirit to weighted conformal inference. In counterfactual conformal prediction, the weighting procedure is used to address the covariate distribution shift between treatment and control groups (i.e. the sampling and target population when fitting model on treatment group observations and make counterfactual prediction on control group individuals).

For counterfactual inference on Y(1), use 1/e(x) as weights; for Y(0), use 1/(1-e(x)).

The ccf has doubly robust properties.

```{r}
# X, Y
# type="mean"
# side=two sided
# outfun
# outparams
# psfun       to be feed into conformalSplit() as wtfun
# psparams
# trainprop

conformalCf_split <- function(X, Y,
                              outfun, outparams,
                              psfun, psparams,
                              trainprop=0.6){
    
    T <- as.numeric(!is.na(Y))
    inds1 <- which(T == 1)
    inds0 <- which(T == 0)
    n1 <- length(inds1)
    n0 <- length(inds0)
    trainid1 <- sample(n1, floor(n1 * trainprop))
    trainid0 <- sample(n0, floor(n0 * trainprop))
    trainid <- c(inds1[trainid1], inds0[trainid0])
    Xtrain <- X[trainid, ,drop=FALSE]
    Ttrain <- T[trainid]

    psparams0 <- psparams
    psparams <- c(list(Y = Ttrain, X = Xtrain), psparams0)
    wtfun <- function(X){
        ps <- do.call(psfun, c(list(Xtest = X), psparams))
        1 / ps
    }

    X <- X[inds1, ,drop=FALSE]
    Y <- Y[inds1]
    out <- conformalSplit(X, Y,
                          outfun, outparams,
                          wtfun,
                          trainprop, trainid1)
    return(out)
}

```


Further subset training set to local support.

```{r}
# s0 is a given location
# for s0 we subset the nearest m support points (by some distance measure, most commonly geo distance) to base the conformal prediction on
# this dist info is already supplied in the A matrix we used for obtaining gps
# the m points can be equally weighted or given a dist decay




```


## Use counterfactual predictions to construct ITE intervals.

If the goal is to obtain ITE for observed samples, since for each individual we already have one potential outcome, the ITEs can be constructed as the differences between the observed outcome and the predicted counterfactual outcomes. It will be more complicated if trying to draw inference on unobserved individuals or even transfer to a new population. This entails predicting all potential outcomes.



